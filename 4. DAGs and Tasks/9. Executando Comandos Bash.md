### Executando Comandos Bash
##




Outro operador amplamente utilizado com o PythonOperator é o BashOperator.

 O BashOperator permite executar comandos bash.

 E gosto de usar o BashOperator para simular falha em uma tarefa.

 E é isso que faremos mais tarde no curso, mas sem mais delongas, vamos implementar o BashOperator.

 Novamente, como sempre, temos que importar o BashOperator.

 Então, vamos digitar: 

 
 ```from airflow.operators.bash import BashOperator```

 
 Assim que tivermos o BashOperator, podemos criar a tarefa logo abaixo, aguardando os dados, vamos adicionar uma nova tarefa.

 Digamos que processing_data seja igual a BashOperator, então um ID de tarefa é igual a processing_data.

 Por último, mas não menos importante, temos que especificar o comando bash que queremos executar.

 Para fazer isso, adicionamos o parâmetro bash_command, encerramos o comando, digamos exit zero, o que significa que essa tarefa sai com o código de retorno zero e assim é bem-sucedida.

 Salve o arquivo e isso é tudo para o BashOperator.



Agora, se verificarmos a interface do usuário do Airflow, vamos voltar para a interface do usuário e clicar em simple_dag.

 Como você pode ver, temos três tarefas, mas se dermos uma olhada na visualização do gráfico, como você pode ver, temos as três tarefas, mas não há dependências entre essas tarefas, o que significa que não sabemos a ordem em que as as tarefas serão executadas.

 Vamos descobrir como consertar isso



##
### Executing Bash Commands
##
Another widely used operator with the PythonOperator, is the BashOperator. The BashOperator allows you to execute bash commands. And I like to use the BashOperator to simulate failure in a task. And that's what we are going to do later in the course but without further ado let's implement the BashOperator. Again, as usual, right there we have to import the BashOperator. So, let's type from airflow.operators.bash import BashOperator. Once we have the BashOperator, we can create the task right under, waiting for data, let's add a new task. Let's say processing_data equals to the BashOperator, then a task ID equals to processing_data. Then last but not least, we have to specify the bash command we want to execute. To do this, we add the parameter bash_command, end the command, let's say exit zero, which means this task exits with the return code zero and so it succeeds. Save the file and that's all for the BashOperator.

Now, if we check the user interface of Airflow, so let's go back to UI and click on simple_dag. As you can see, we have three tasks, but if we take a look at the graph view, as you can see we have the three tasks, but no dependencies between those tasks, which means we don't know the order in which the tasks are going to be executed. Let's find out how to fix thi-

