### Jogando com o start_date
##

De volta ao nosso pipeline de dados. Vamos brincar um pouco com a data de início. E a primeira pergunta é, qual é o valor padrão para a data de início? Bem, não há um valor padrão ou, na verdade, existe um que seja conhecido. E podemos verificar isso criando nossa primeira tarefa. Vamos importar um operador. Vamos digitar de airflow.operators.dummy import DummyOperator. E se você não sabe o que é o operador Dummy. Bem, basicamente é um operador que não faz nada. É muito bom se você quiser fazer algumas experiências. O operador Dummy é bom para isso. Então aqui, vamos criar nossa primeira tarefa. Task_1 = para DummyOperator e você deve especificar um ID de tarefa. Digamos que task_ID= para task_1. O ID da tarefa em todos os seus operadores para fornecer dag deve ser exclusivo.

Defina o arquivo e vamos para a interface do usuário. Recarregue a página. Temos que esperar um pouco, até que as modificações sejam levadas em consideração. E como você pode ver, temos uma flecha. Se você expandir esta pequena caixa, obtemos que a tarefa está sem o parâmetro de data de início. E esta mensagem é importante porque indica que uma tarefa, ou um operador espera uma data de início. Mas vamos voltar a essa noção mais adiante no vídeo.

Por enquanto, vamos definir a data de início. Como definir uma data de início? Vamos voltar ao nosso Dag. Para criar uma data de início. Você precisa importar o objeto de data e hora. Para fazer isso, digite from datetime import date time. Depois de ter o objeto datetime, aqui você só precisa especificar o parâmetro de data de início no objeto dag. Por exemplo, aqui, start_date = para um objeto datetime e digamos que queremos a data de 1º de janeiro de 2021.

Digitamos 2021 1, 1. E pronto. É assim que você pode definir uma data de início para um fluxo de ar do pipeline de dados. Aqui, o pipeline de dados, simple_dag, começará a ser agendado em 1º de janeiro de 2021. Agora, como vimos na mensagem, uma tarefa também espera uma data de início. Mas o problema é que, se salvarmos o arquivo e voltarmos para a interface do usuário. Em seguida, atualize a página e agora ele se foi. Na verdade, se você especificar a data de início diretamente no objeto dag, essa data de início será aplicada a todos os seus operadores.

Mas isso leva a outra questão. Isso significa que podemos definir diferentes datas de início em nosso pipeline de dados? Podemos definir uma data de início no nível Dag e outra data de início no nível do operador? Vamos descobrir. Por exemplo, aqui, você definitivamente poderia fazer isso. A data de início é igual ao objeto de data e hora e, digamos, 1º de janeiro ou, na verdade, 2 de janeiro de 2021. Assim. Você pode definitivamente fazer isso, mas nunca fará isso.

Por que? Porque isso significa que você tem tarefas diferentes com datas de início diferentes. E eles não devem ser acionados ao mesmo tempo. Na verdade, não há nenhum caso de uso em que você precise fazer isso. Nunca faça isso. Mas é importante lembrar que você não pode fazer isso no fluxo de ar. Você pode ter várias datas de início em seu Dag, pois o parâmetro de data de início pode ser definido no nível do operador.

Vamos remover essa modificação, pois você nunca fará isso. Podemos removê-lo. E agora sabemos como definir uma data de início e o fato de que um operador precisa de uma data de início. Qual o proximo? Bem, a outra coisa que você precisa saber é que, por padrão, a data e a hora estão em UTC e todas as datas no fluxo de ar são armazenadas em UTC. E esta é realmente a sua melhor prática. Eu recomendo fortemente que você sempre armazene suas datas em UTC em seu banco de dados.

Por que? Porque evitará muitos problemas com fusos horários. O que significa concretamente? Bem, isso significa que essas datas estão em UTC. Se eu quiser acionar efetivamente meu dia, 1º de janeiro de 2021 à meia-noite, no meu fuso horário local, na verdade, tenho que modificar essa data aqui. Se dermos uma olhada na interface do usuário. Ali, você pode ver a data atual em UTC, e aqui você tem meu fuso horário, mais quatro horas. Se você clicar nele, podemos ver a data atual no meu fuso horário local. Como tenho mais quatro horas, volto ao código. Para acionar esse dia, para começar a escalar esse dia, 1º de janeiro de 2021 no meu fuso horário local, tenho que colocar 2020 e 12 horas. Ao fazer isso, esse pipeline de dados começará a ser agendado para 1º de janeiro de 2021 no meu fuso horário local.

Mas, como prática recomendada, recomendo fortemente que você mantenha todas as suas datas em UTC. Em vez de fazer isso, apenas mantenha suas datas em UTC. É muito mais fácil lidar com suas datas. A data de início está em UTC. O que mais podemos fazer? Bem, você também pode definir uma data de início no futuro. Se você definir uma data de início no futuro, digamos 22 aqui. Bem, este dia começará a ser agendado, 1º de janeiro de 2022. Antes não. Agora, e se definirmos essa data de início no passado? Digamos 2019. Bem, por padrão, o fluxo de ar executará todas as execuções não acionadas dag entre a data atual e a data de início. Como não definimos o intervalo [inaudível 00:06:22] aqui, o valor padrão do intervalo [inaudível 00:06:25] é diário. Vamos acabar com muitos dag é executado ao mesmo tempo. E este é o comportamento padrão do fluxo de ar.

Sempre que você tiver uma data de início no passado e seu pipeline de dados ainda não tiver sido acionado. Assim que você começar a agendá-lo, o fluxo de ar acionará todas as execuções não acionadas dag entre a data de início e a data atual. Tenha cuidado com isso. E veremos mais adiante no curso como modificar isso.

Tudo bem. A última coisa que gostaria de falar é sobre o fato de que você nunca deve definir a data de início dinamicamente. Isso significa que não faça isso. Datetime.now. Não faça isso. Por que? Porque se você se lembra de como seus dias são programados no vídeo anterior. A data de início foi alterada e o problema é que seu dag foi acionado. Seu dag é efetivamente acionado quando a data de início e o intervalo de agendamento são decorridos. Mas se sua data de início for definida com datetime.now, bem, toda vez que o pipeline de dados for avaliado pelo agendador. A data de início também é modificada. Em teoria, você nunca será capaz de acionar seu dag, pois a data de início avança constantemente. Tenha em mente, sempre defina uma data e hora estática e nunca use agora. Isso é tudo que você precisa saber sobre a data de início.

Vamos descobrir o segundo parâmetro definido com a data de início, que é o intervalo de agendamento.

##
### Playing with the start_date
##
Back to our data pipeline. Let's play a little bit with the start date. And the first question is ,what is the value by default for the start date? Well, there is no default value, or actually there is one which is known. And we can verify this by creating our first task. Let's import an operator. Let's type from airflow.operators.dummy import DummyOperator. And if you don't know what the Dummy operator is. Well, basically it is an operator that does nothing. It's pretty fine if you want to make some experiments. The Dummy operator is nice for that. Then here, let's create our first task. Task_1 = to DummyOperator and you have to specify a task ID. Let's say task_ID= to task_1. The task ID in all of your operators for giving dag must be unique.

Set the file, and let's go to the user interface. Refresh the page. We have to wait a little bit, until the modifications are taken into account. And as you can see, we got an arrow. If you expand this little box, we obtain task is missing the start date parameter. And this message is important because it indicates that a task, or an operator expects a start date. But we are going to go back at this notion later in the video.

For now, let's define the start date. How can you define a start date? Let's go back to our Dag. In order to create a start date. You need to import the date time object. To do that, right there, type from datetime import date time. Once you have the datetime object, here you just need to specify the start date parameter in the dag object. For example, here, start_date = to a datetime object, and let's say we want the date of the 1st of January, 2021.

We type 2021 1, 1. And that's it. That's how you can define a start date for a data pipeline airflow. Here, the data pipeline, simple_dag will start being scheduled the 1st of January, 2021. Now, as we've seen from the message, a task expects a start date as well. But the thing is, if we save the file, and go back to the UI. Then refresh the page, and now it's gone. In fact, if you specify the start date directly in the dag object, well this start date is applied to all of your operators.

But this leads to another question. Does this means that we can define different start dates in our data pipeline? Can we define a start date at the Dag level, and another start date at the operator level? Let's find out. For example, here, you could definitely do that. Start date equals to date time object, and then let's say the 1st of January, or actually the 2nd of January, 2021. Like that. You can definitely do that, but you will never do that.

Why? Because it means that you have different tasks having different start date. And they shouldn't be triggered at the same time. Actually, there is no use case where you might need to do that. Never do that. But it is important to remember that you can't do it in airflow. You can have multiple start dates in your Dag, as the start date parameter can be defined at the operator level.

Let's remove this modification as you will never do that. We can remove it. And now we know how to define a start date, and the fact that an operator needs a start date. What next? Well, the other thing you have to know is that by default, the date time is in UTC, and all dates in airflow are stored in UTC. And this is really your best practice. I strongly advise you to always store your dates in UTC in your database.

Why? Because it will avoid you a lot of troubles with time zones. What does it mean concretely? Well, it means that these dates right there is in UTC. If I want to effectively trigger my dag, the 1st of January, 2021 at midnight, in my local time zone, actually I have to modify this date here. If we take a look at the user interface. Right there, you can see the current date in UTC, and here you have my time zone, plus four hours. If you click on it, we can see the current date in my local timezone. As I have plus four hours, back to the code. In order to trigger that dag, in order to start scaling that dag, the 1st of January, 2021 in my local timezone, I have to put 2020, and 12 hours. By doing this, these data pipeline will start being scheduled the 1st of January, 2021 in my local time zone.

But as a best practice, I strongly recommend you to keep all of your dates in UTC. Instead of doing this, just keep your dates in UTC. It is much easier to deal with your dates. The start date is in UTC. What else can we do? Well, you can define a start date in the future as well. If you define a start date in the future, let's say 22 here. Well, this dag will start being scheduled, the 1st of January, 2022. Not before. Now, what about if we set this start date way in the past. Let's say 2019. Well, by default airflow will run all the non trigger dag runs between the current date, and the start date. As we didn't define the [inaudible 00:06:22] interval here, and the default value of the [inaudible 00:06:25] interval is daily. We will end up with many dag runs running at the same time. And this is the default behavior of airflow.

Whenever you have a start date in the past, and your data pipeline hasn't been triggered yet. As soon as you start scheduling it, airflow will trigger all the non-trigger dag runs between the start date, and the current date. Be careful with that. And we will see later in the course how to modify this.

All right. The last thing I would like to talk about is the fact that you should never define the start date dynamically. That means don't do that. Datetime.now. Don't do that. Why? Because if you remember the way your dags are scheduled in the previous video. The start date is shifted, and the thing is your dag is triggered. Your dag is effectively triggered once the start date, plus the scheduling interval is elapsed. But if your start date is defined with datetime.now, well, each time the data pipeline is evaluated by the scheduler. The start date is modified as well. In theory, you will never be able to trigger your dag as the start date constantly move forward. Keep in mind, always define a static date time, and never use now. That's all you need to know about the start date.

Let's discover the second parameter defined with the start date, which is the schedule interval.


