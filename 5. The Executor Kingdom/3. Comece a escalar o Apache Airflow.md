### Comece a escalar o Apache Airflow
##
Vimos que o executor sequencial é perfeito para fins de experimentação ou depuração, pois permite executar apenas uma tarefa após a outra sequencialmente. Mas agora, se você deseja executar o Airflow [inaudível 00:00:13], há uma boa chance de executar mais de uma tarefa em paralelo. Então, como você pode fazer isso? Qual executor você deve tentar primeiro?

Bem, eu recomendo fortemente que você tente o executor local. O executor local permite que você execute várias tarefas ao mesmo tempo em sua instância do Airflow, desde que você tenha apenas uma máquina. Basicamente, toda vez que sua tarefa precisa ser acionada, o executor local cria um subprocesso e, nesse subprocesso, a tarefa é executada.

Portanto, a simplicidade do executor local é o motivo de ele ser tão poderoso. Você só precisa configurar o banco de dados do Airflow com o Postgres, por exemplo, e alterar o parâmetro executor para local executor e está pronto para começar a escalar o Airflow e executar quantas tarefas os recursos da sua máquina permitirem. Portanto, sim, a limitação do executor local são os recursos que você possui em sua única máquina.

E, a menos que você tenha uma máquina quântica, não poderá executar quantas tarefas quiser. É neste ponto que você pode pensar em outro executor, que é mais complexo de configurar, mas desta vez você poderá executar um número infinito de tarefas.

Vamos descobrir qual é.

##
### Start Scaling Apache Airflow
##
We have seen that the sequential executor is perfect for experimenting or debugging purposes, as it allows you to only execute one task after the other sequentially. But now, if you want to run Airflow [inaudible 00:00:13], there is a good chance that you want to execute more than one task in parallel. So how can you do that? Which executor should you try first?

Well, I strongly advise you to try the local executor. The local executor allows you to execute multiple tasks at the same time in your Airflow instance, as long as you have only one machine. Basically each time your task needs to be triggered, the local executor creates a subprocess, and in that subprocess, the task is executed.

So the simplicity of the local executor is why it is so powerful. You only need to configure the database of Airflow with Postgres, for example, and change the parameter executor to local executor and you are ready to start scaling Airflow and to execute as many tasks as the resources on your machine allow you to execute. Therefore, yes, the limitation of the local executor is the resources you have on your single machine. 

And unless you have a quantic machine, you won't be able to run as many tasks as you want. It is at this point that you might think of another executor, which is more complex to set up, but this time you will be able to run an infinite number of tasks. 

Let's discover which one it is.

