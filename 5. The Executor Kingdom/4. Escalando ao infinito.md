### Escalando ao infinito!
##
Há uma boa chance de que em algum momento você não tenha processos suficientes para executar quantas tarefas precisar ao mesmo tempo em sua instância, e essa é a limitação dos executores locais. Então, quais executores você deve usar? Normalmente, o primeiro executor a ser configurado, assim que quisermos executar quantas tarefas quisermos, é o executor celery. E com o executor de aipo, você executa suas tarefas em um cluster de salário. Se você não sabe o que é o aipo, pode pensar no aipo como uma fila de tarefas distribuídas, permitindo que você distribua suas tarefas em várias máquinas. E assim suas tarefas serão executadas nessas várias máquinas e não em uma única máquina, como no executor executivo local. Mas deixe-me mostrar o tipo de arquitetura que você pode ter. Digamos que você tenha nós diferentes. Então, nó 1, depois nó 2, nó 3, 4 e 5. Essas são suas máquinas.

Uma coisa que você pode ter é o servidor web e o agendador do airflow, ambos rodando em uma única máquina como o nó 1. Então no nó 2, você pode ter o banco de dados do banco de dados de metadados do airflow rodando, digamos Postgres. Então isso é bem normal. Quero dizer, você sempre terá esses três componentes, mas com o executor celery, há um componente adicional que você precisa configurar, que é a Fila. Você precisa usar uma ferramenta de terceiros como RabbitMQ ou Redis. Para criar a Fila, onde suas tarefas serão empurradas pelo executor do aipo e onde serão puxadas pelos trabalhadores. Nesse caso, além dos três componentes principais do fluxo de ar, você tem o quarto, que é a Fila. Depois de configurar a fila, ainda falta algo. De fato, para as três máquinas ali. Você ainda precisa especificar que pode executar tarefas de fluxo de ar nessas máquinas. Como você pode fazer isso? Ao executar o comando: ```airflow celery worker``` em cada máquina. E então, depois de fazer isso, cada máquina terá um trabalhador de aipo ou fluxo de ar ... assim.

Depois de enviar uma tarefa para executá-la, essa tarefa é enviada pelo agendador para a fila. E então o trabalhador, um dos trabalhadores vai puxar aquela tarefa da fila e executar a tarefa dentro da máquina, dentro do trabalhador. É assim que funciona. E é por isso que você pode executar quantas tarefas quiser. De fato, a única coisa que você precisa, se tiver mais tarefas a executar, é adicionar outra máquina com outro trabalhador. E você acabou de permitir que mais tarefas sejam executadas em paralelo. Portanto, cada vez que você precisar de mais recursos, adicione uma nova máquina. É por isso que podemos dizer que podemos escalar ao infinito com o executor celery. Mas lembre-se de que você precisa configurar um componente adicional, que é a Fila. Na verdade, existe também um broker de resultado, que é basicamente o mesmo banco de dados que usamos para o airflow.

Portanto, este onde o resultado da tarefa será interrompido. Agora você deve ter cuidado com as dependências. De fato, como temos várias máquinas, nó 3, 4, 5 e 6 em cada máquina, o fluxo de ar deve ser instalado. Caso contrário, você não conseguirá executar o comando: ```airflow celery worker```, mas isso não é tudo. Depois de instalar o fluxo de ar em todas essas máquinas, você deve certificar-se de que as dependências necessárias para seus dags também estejam instaladas. Caso contrário, você acabará com um erro. Então, se você tiver, digamos, a máquina quatro com a biblioteca Python, Boto3, para interagir com a AWS, mas essa biblioteca de patentes não existe ou não está instalada na máquina três. Bem, se uma das tarefas interage com o Boto3, mas esta tarefa é executada na máquina três. Nesse caso, você acabará com um erro. Portanto, você deve garantir que todas as máquinas compartilhem as mesmas dependências.

Todas as máquinas têm as mesmas dependências instaladas. Caso contrário, há uma boa chance de acabar com falhas. Lembre-se de que o executor do aipo é extremamente poderoso. Você pode executar quantas tarefas quiser com SLAs rígidos. E este é um dos executores mais confiáveis e comumente usados com fluxo de ar. Portanto, neste ponto, os diferentes executores que você pode usar, dependendo de seus casos de uso, bem como da arquitetura que você possui, são o executor sequencial, o executor local ou o executor celery. Eu sei que existe o executor do Kubernetes, mas não vamos falar sobre isso porque o Kubernetes é uma fera. Portanto, você precisa garantir que sua equipe conheça o Kubernetes para usá-lo da melhor maneira possível.

##
### Scaling to the Infinity!
##
There is a good chance that at some point you might not have enough processes to execute as many tasks as you need at the same time in your for instance, and that's the limitation of the local executors. So what executors should you use instead? Usually, the first executor to set up, as soon as we want to execute as many tasks as we want, is the celery executor. And with the celery executor, you execute your tasks on a salary cluster. If you don't know what celery is, you can think of celery as a distributed task queue, allowing you to distribute your tasks on multiple machines. And so your tasks are going to be executed on those multiple machines and not on a single machine, like with the local executive executor. But let me show you the kind of architecture you might have. Let's say you have different nodes. So node 1, then node 2, node 3, 4 and 5. So that's your machines.

One thing you might have is the web server and the scheduler of airflow, both running on a single machine like node 1. Then in the node 2, you might have the database of the metadata database of airflow running, let's say Postgres. So that's pretty usual. I mean, you will always have those three components, but with the celery executor, there is one additional component that you have to set up, which is the Queue. You have to use a third party tool like RabbitMQ or Redis. In order to create the Queue, where your tasks will be pushed by the celery executor and where they will be pulled by the workers. So in that case, in addition to the three core components of airflow, you have the fourth one, which is the Queue. Once you have the Queue setup, there is still something missing. Indeed, for the three machines right there. You still have to specify that you can execute airflow tasks on those machines. How can you do that? By executing the comment, airflow celery worker on each machine. And then once you have done that, each machine will have a celery or airflow worker... like that.

Once you push a task to execute it, this task is pushed by the scheduler into the queue. And then the worker, one of the workers will pull that task from the queue and execute the task inside the machine, inside the worker. That's how it works. And that's why you can execute as many tasks as you want. Indeed, the only thing you need, if you have more tasks to execute is to add another machine with another worker. And you've just allowed more tasks to be executed in parallel. So each time you need more resources, you add a new machine. That's why we can say we can scale to the infinity with the celery executor. But remember you have to set up an additional component, which is the Queue. Actually, there is also a result broker, which is basically the same database as we use for airflow.

So this one where the result of the task will be stopped. Now you should be careful with the dependencies. Indeed, as we have multiple machines, node 3, 4, 5, and 6 on each machine, airflow must be installed. Otherwise, you won't be able to execute the command airflow celery worker, but that's not all. Once you have installed airflow on all of those machines, you have to make sure that the dependencies needed by your drags are installed as well. Otherwise, you will end up with an error. So if you have, let's say machine four with the Python library, Boto3, to interact with AWS, but this patent library doesn't exist or is not installed on the machine three. Well, if one of the task interacts with Boto3, but this task is executed on machine three. In that case, you will end up with an error. So you have to make sure all machines share the same differences.

All machine have the same dependencies installed. Otherwise, there is a good chance that will end up with failures. Keep in mind that the celery executor is extremely powerful. You can execute as many tasks as you want with Tight SLAs. And this is one of the most reliable and commonly used executor with airflow. So at this point, the different executors you might use depending on your use cases, as well as the architecture you have, these are the sequential executor, the local executor or the celery executor. I know there is the Kubernetes executor, but we are not going to talk about it because Kubernetes is a beast. Therefore, you have to make sure your team knows Kubernetes to use it in the best possible way.

