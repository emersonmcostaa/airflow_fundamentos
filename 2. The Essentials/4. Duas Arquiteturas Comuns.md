### Duas Arquiteturas Comuns
##

Existem milhares de arquiteturas diferentes. 

Obviamente, não vou mostrar todas elas no vídeo porque é impossível, mas gostaria de mostrar as duas arquiteturas mais comuns que você pode ter com o Apache Airflow. 

Portanto, vamos começar com a primeira e mais simples arquitetura que você terá assim que configurar e executar o Airflow pela primeira vez. 

Essa arquitetura é a Arquitetura de Nó Único. 

[imagem ONE NODE]

Como você pode ver, todos os componentes do airflow rodam na mesma máquina, o servidor web, o metastore ou o metadatabase, o agendador e o executor. 

Então, como os diferentes componentes funcionam juntos?

Primeiro, o servidor web interage com o metastore ou o metadatabase. 

Basicamente, o servidor da Web busca todos os dados de que precisa no metastore. 

Por exemplo, o status de suas tarefas ou usuários, as permissões e assim por diante, todos os dados que você pode ver do servidor da Web, da interface do usuário, vêm do metastore. 

Então, você tem o agendador. 

Se uma tarefa estiver pronta para ser agendada, o agendador mudará o status dessa tarefa no metastore, então um Objeto de Instância de Tarefa será criado e esse objeto de Instância de Tarefa será enviado do agendador para o executor. 

E mais especificamente na fila do executor, e é lá que a tarefa estará pronta para ser buscada por um walker e assim executada. 

Por último, mas não menos importante, o executor também interage com o metastore para atualizar o status da tarefa. 

Assim que a tarefa é concluída, o status dessa tarefa é alterado pelo executor e não pelo agendador. 

A partir desse esquema, você pode ver que o servidor web, o agendador e o executor interagem com o metabanco.

No entanto, o servidor web não interage diretamente com o escalonador e o executor. 

Portanto, essa é a arquitetura padrão com a qual você terminará assim que configurar e executar o fluxo de ar pela primeira vez. 

E esta é obviamente a arquitetura mais simples que você pode ter, mas e se você quiser começar a dimensionar o Airflow? 

E se você quiser executar quantas tarefas quiser? 

Obviamente, você precisará configurar uma nova arquitetura e esse é exatamente o objetivo da arquitetura de vários nós.

Então, vamos imaginar que você tenha um cluster de pesquisa e deseja executar suas tarefas usando o executor de pesquisa.

Normalmente, você terá vários nós, por exemplo, número. 

Um com o servidor web, o agendador e o executor rodando como na arquitetura de nó único. 

Mas agora você pode perguntar, onde está a fila? Onde está o metabanco? Bem, desta vez o meta banco de dados e a fila estão rodando dentro de um novo nó.

Uma coisa que você deve lembrar é que, com o executor do cellule, a fila é externa ao executor, o que significa que, para configurar e executar a fila onde as tarefas serão enviadas e colocadas, você precisará de uma ferramenta de terceiros como o rabbitM-Q já tenha em mente com o executor da célula. 

Você precisa de uma ferramenta de terceiros para configurar e executar a fila onde as tarefas serão enviadas e colocadas, uma vez que você tenha esses componentes em execução no nó dois, o último componente necessário é um trabalhador do Airflow. 

E como você tem várias máquinas, você terá vários airflow workers onde suas tarefas serão executadas. 

Portanto, desta vez, em vez de ter suas tarefas executadas dentro do nó, uma ou duas, como na arquitetura de nó único, suas tarefas serão executadas dentro dos diferentes nós do Walker. 

Em vez disso, os diferentes trabalhadores do Airflow.

Isso é o que você pode ver de lá.

Agora, como funciona bem, como na arquitetura de nó único, o servidor da Web interage com o armazenamento do medidor e, em seguida, o agendador interage com o armazenamento do medidor, bem como com o executor. 

Quando uma tarefa está pronta para ser agendada, essa tarefa é enviada ao executor e o executor envia a tarefa para a fila.

Assim que a tarefa estiver na fila, ela estará pronta para ser puxada e executada por um dos trabalhadores. 

Essa arquitetura é mais complexa do que a arquitetura de nó único, mas nessa arquitetura você pode executar quantas tarefas quiser. 

De fato, se você precisar de mais recursos, basta adicionar um novo Airflow Worker e estará pronto para executar mais tarefas. 

Tudo bem, agora descobrimos as duas arquiteturas mais comuns com o Apache Airflow, a arquitetura de nó único e a arquitetura de vários nós. 

Descobrimos como os diferentes componentes funcionam juntos nas diferentes arquiteturas, mas ainda há uma única coisa.

De fato. 

Não sabemos o que acontece quando uma tarefa está pronta para ser acionada. Bem, vamos descobrir no próximo vídeo.


### 2 Common Architectures
##

There are thousands of different architectures. Obviously, I'm not going to show you all of them in the video as it is impossible, but I would like to show you the two most common architectures you can have with Apache Airflow. So let's begin with the first and most simple architecture you will have as soon as you set up and run Airflow for the first time. This architecture is the Single-Node Architecture. As you can see all the components of airflow run on the same machine, the web server, the metastore or the metadatabase, the scheduler and the executor. So how the different components work together?

First, the web server interacts with the metastore or the metadatabase. Basically, the web server fetches all the data it needs from the metastore. For example, the status of your tasks or the users, the permissions, and so on, all the data that you can see from the web server, from the user interface comes from the metastore. Then, you have the scheduler. If a task is ready to be scheduled, the scheduler will change the status of that task in the metastore, then a Task Instance Object is created and that Task Instance object is sent from the scheduler into the executor. And more specifically into the queue of the executor, and that's where the task will be ready to be fetched by a walker and so executed. Last but not least, the executor interacts with the metastore as well in order to update the task status. As soon as the task is done, the status of that task is changed by the executor and not by the scheduler. From this schema, you can see that the web server, the scheduler, and the executor, all of them interact with the metadatabase.

However, the web server does not interact directly with the scheduler and the executor. So that's the default architecture you will end up with as soon as you set up and run airflow for the first time. And this is obviously the simplest architecture you can have, but what about if you want to start scaling Airflow? What about if you want to execute as many tasks as you want? Obviously, you will need to set up a new architecture and that's exactly the purpose of the multi-nodes architecture.

So let's imagine you have a survey cluster and you want to execute your tasks using the survey executor. Typically you will have multi-nodes, for example, number. One with the web server, the scheduler and the executor running like with the single-node architecture. But now you can ask, where is the queue? Where is the metadatabase? Well, this time the meta database and the queue are running inside a new node.

One thing you have to remember that with cellule executor, the queue is external to the executor, which means in order to set up and run the queue where the tasks will be pushed and put, you will need a third party tool like rabbit M-Q already keep in mind with the cell executor. You need a third party tool in order to set up and run the queue where the tasks will be pushed and put, once you have those components running in the node two, the last component you need is an Airflow worker. And as you have multiple machines, you will have multiple airflow workers where your tasks will be executed. So this time, instead of having your tasks executed inside the node, one or two, like with the single-node architecture, your tasks will be executed inside the different Walker nodes. Instead, the different Airflow workers. That's what you can see from there.

Speaker 3 (03:33):
Now, how it works well, like with the single-node architecture, the web server interacts with the meter store and then the scheduler interacts with the meter store, as well as the executor. Once a task is ready to be scheduled, that task is sent to the executor and the executor sends the task into the queue. Once the task is in the queue, that task is ready to be pulled and executed by one of the workers. This architecture is more complex than the single-node architecture, but in that architecture, you can execute as many tasks as you want. Indeed, if you need more resources, you just need to add a new Airflow Worker and you are ready to execute more tasks. All right, now we've discovered the two most common architectures with Apache Airflow, the single-node architecture and the multi-nodes it's architecture. We've discovered how the different components work together in the different architectures, but there is still one single thing. Indeed. We don't know what happens when a task is ready to be triggered. Well, let's find out in the next video.
